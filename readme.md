# Machine Learning Interpretability

Interpret means to "explain" or to present in understandable terms. The ability to express in understandable terms, what the model has learned and the reasons that affect their output.

Interpretability is about the extent to which a cause and effect can be observed within a system. Or to put it another way, it is the extent to which you are able to predict what is going to happen, given a change in input or algorithmic parameters. It's being able to understand which inputs are the most predictive (i.e., impact the prediction/output the most), and anticipate how predictions will change with differing inputs.

Machine learning interpretability = knowledge. Often, there is no point in knowing how to put it into code and run it without knowing how to extract knowledge from it, we need to understand what is being done to extract knowledge for your business and then obtain valuable insights!

* If a customer is rejected a loan, we can say why.
* If an insurance provides a certain premium, we know the reasons.
* If we diagnose a patient with a certain disease, we can tell them why.